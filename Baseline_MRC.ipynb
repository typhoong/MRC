{"cells":[{"cell_type":"markdown","metadata":{"id":"74d0cf9f-03f5-4446-be51-a96049fa0121"},"source":["# 문서 검색 효율화를 위한 기계독해\n","- 자연어 기계독해(Machine Reading Comprehension) 과제"],"id":"74d0cf9f-03f5-4446-be51-a96049fa0121"},{"cell_type":"markdown","metadata":{"id":"NWNHSk-pSskv"},"source":["## 데이터 구조\n","\n","```\n","$ MRC/\n","├── DATA/\n","│   ├── train.json\n","│   ├── test.json\n","│   └── sample_submission.csv\n","├── prediction.csv (코드 실행 후 생성)\n","├── results/ (코드 실행 후 생성)\n","```"],"id":"NWNHSk-pSskv"},{"cell_type":"markdown","metadata":{"id":"xidLcL3yK3wm"},"source":["#0. 사전 준비"],"id":"xidLcL3yK3wm"},{"cell_type":"markdown","metadata":{"id":"qPmVS-p6K992"},"source":["##0.1 구글 드라이브 마운트"],"id":"qPmVS-p6K992"},{"cell_type":"code","execution_count":null,"metadata":{"id":"VHgjTjglFXf8"},"outputs":[],"source":["# 구글 Colaboratory 를 사용하기 위해 구글 계정으로 로그인합니다. \n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"VHgjTjglFXf8"},{"cell_type":"markdown","metadata":{"id":"bYuiNxj7LQgH"},"source":["##0.2 라이브러리 설치"],"id":"bYuiNxj7LQgH"},{"cell_type":"code","execution_count":null,"metadata":{"id":"OchkeVlBLK_8"},"outputs":[],"source":["!pip install transformers"],"id":"OchkeVlBLK_8"},{"cell_type":"markdown","metadata":{"id":"420e527f-ff52-4bb3-a260-565fe2f91e2d"},"source":["##1. 라이브러리 불러오기"],"id":"420e527f-ff52-4bb3-a260-565fe2f91e2d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5b80416a-1082-4ae9-8057-18eb163dfc15"},"outputs":[],"source":["import os\n","import sys\n","import csv\n","import copy\n","import json\n","import random\n","import shutil\n","import numpy as np\n","import pandas as pd\n","from time import time\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score\n","from datetime import datetime, timezone, timedelta\n","\n","from transformers import ElectraTokenizerFast\n","from transformers import ElectraForQuestionAnswering\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"],"id":"5b80416a-1082-4ae9-8057-18eb163dfc15"},{"cell_type":"markdown","metadata":{"id":"e031838b-d5ad-4887-ae60-07ff98a71a0a"},"source":["##2. 하이퍼파라미터 및 기타인자 설정"],"id":"e031838b-d5ad-4887-ae60-07ff98a71a0a"},{"cell_type":"markdown","metadata":{"id":"9e7be91e-9928-453e-8aeb-a6af032b7dcb"},"source":["###2.1 데이터 경로"],"id":"9e7be91e-9928-453e-8aeb-a6af032b7dcb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2bee580a-4c2a-42b4-9f1d-78b8d5e63981"},"outputs":[],"source":["PROJECT_DIR = '/content/drive/MyDrive/MRC' # 프로젝트 디렉토리 설정\n","DATA_DIR= '/content/drive/MyDrive/MRC/DATA' # 데이터 디렉토리 설정"],"id":"2bee580a-4c2a-42b4-9f1d-78b8d5e63981"},{"cell_type":"markdown","metadata":{"id":"f923389a-631d-4a17-8542-382fa0d6e68b"},"source":["###2.2 시드 설정"],"id":"f923389a-631d-4a17-8542-382fa0d6e68b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"97cb0fc4-cce7-45b7-876d-84d00a32f68c"},"outputs":[],"source":["# 난수 생성기가 항상 일정한 값을 출력하게 하기 위해 seed 고정\n","RANDOM_SEED = 42\n","\n","torch.manual_seed(RANDOM_SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)"],"id":"97cb0fc4-cce7-45b7-876d-84d00a32f68c"},{"cell_type":"markdown","metadata":{"id":"88051bcc-8a4e-4552-af85-4fb62d9e2658"},"source":["###2.3 하이퍼파라미터 설정"],"id":"88051bcc-8a4e-4552-af85-4fb62d9e2658"},{"cell_type":"code","execution_count":null,"metadata":{"id":"42d42463-8bf9-4ea7-a42a-72f763adb515"},"outputs":[],"source":["LEARNING_RATE = 5.0e-4     # 학습률(learning rate)은 경사하강법(gradient descent)을 통해 내리막길을 내려갈 때의 보폭\n","BATCH_SIZE = 16     # 배치(batch)는 모델의 가중치(weights)를 업데이트하는 학습 데이터의 단위. 여기서는 16개를 학습할 때마다 모델의 가중치(weights)를 업데이트한다는 것\n","PIN_MEMORY = True\n","NUM_WORKERS = 0\n","EPOCHS = 2     # 에폭은 전체 학습 데이터를 학습에 사용하는 횟수. 주어진 학습 데이터를 여러번 학습할 수 있음\n","DROP_LAST = False\n","EARLY_STOPPING_MODE = min\n","EARLY_STOPPING_PATIENCE = 10\n","EARLY_STOPPING_TARGET = 'val_loss'     # validation set의 loss를 기준으로 early_stopping 여부를 결정할 것\n","LOGGING_INTERVAL = 200"],"id":"42d42463-8bf9-4ea7-a42a-72f763adb515"},{"cell_type":"markdown","metadata":{"id":"01a3191b-b482-4f9f-85e0-be96c5f09824"},"source":["###2.4 디바이스 설정"],"id":"01a3191b-b482-4f9f-85e0-be96c5f09824"},{"cell_type":"code","execution_count":null,"metadata":{"id":"626e7afa-2a56-4094-9e75-cfb3bec09606"},"outputs":[],"source":["os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"id":"626e7afa-2a56-4094-9e75-cfb3bec09606"},{"cell_type":"markdown","metadata":{"id":"863de192-3f18-421f-a06f-a5964bdbeb87"},"source":["##3. Dataset 정의"],"id":"863de192-3f18-421f-a06f-a5964bdbeb87"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2c5fa64b-a355-43d2-95dc-94bb8605cc15"},"outputs":[],"source":["class QADataset(Dataset):     # 데이터를 input으로 변환해주는 Dataset 클래스를 상속하여, QA(Question Answering) 과제에 맞게 커스터마이징한다\n","    \n","    def __init__ (self, data_dir: str, tokenizer, max_seq_len: int, mode = 'train'):     # Dataset 클래스는 기본적으로 __init__, __len__, __getitem__를 정의해 주어야 한다\n","        self.mode = mode\n","        self.data = json.load(open(data_dir, 'r', encoding='utf8'))\n","        \n","        self.tokenizer = tokenizer\n","        self.max_seq_len = max_seq_len\n","        \n","        if mode == 'test':\n","            self.encodings, self.question_ids = self.preprocess()\n","        else:\n","            self.encodings, self.answers = self.preprocess()\n","        \n","    def __len__(self):     # index를 통해 input을 순차적으로 읽어오기 위해서는 데이터의 길이가 먼저 확인되어야 한다. __len__ 함수는 input의 길이를 반환해주는 함수\n","        return len(self.encodings.input_ids)\n","\n","    def __getitem__(self, index: int):     # input의 길이가 확인되면 index를 통해 데이터를 불러올 수 있다. __getitem__ 함수는 index에 해당하는 input 데이터를 반환해주는 함수\n","        return {key: torch.tensor(val[index]) for key, val in self.encodings.items()}\n","\n","    \n","    def preprocess(self):\n","        contexts, questions, answers, question_ids = self.read_squad()     # SQuAD(Stanford Question Answering Dataset) 형식의 데이터에서 contexts, questions, answers, question_ids를 읽어오는 함수\n","        if self.mode == 'test':\n","            encodings = self.tokenizer(contexts, questions, truncation=True, max_length = self.max_seq_len, padding=True)\n","            return encodings, question_ids\n","        else: # train or val\n","            self.add_end_idx(answers, contexts)     # train.json에는 질문에 대한 답이 context 내에서 시작되는 index인 'answer_srart'만 있기 때문에, 추가로 'answer_end'를 찾아주는 함수\n","            encodings = self.tokenizer(contexts, questions, truncation=True, max_length = self.max_seq_len, padding=True)\n","            self.add_token_positions(encodings, answers)\n","        \n","            return encodings, answers\n","        \n","    \n","    def read_squad(self):     # SQuAD(Stanford Question Answering Dataset) 형식의 데이터에서 contexts, questions, answers, question_ids를 읽어오는 함수\n","        contexts = []\n","        questions = []\n","        question_ids = []\n","        answers = []\n","        \n","        # train - val split\n","        if self.mode == 'train':\n","            self.data['data'] = self.data['data'][:-1*int(len(self.data['data'])*0.1)]\n","        elif self.mode == 'val':\n","            self.data['data'] = self.data['data'][-1*int(len(self.data['data'])*0.1):]\n","        \n","        \n","        till = len(self.data['data'])\n","        \n","\n","        for group in self.data['data'][:till]:\n","            for passage in group['paragraphs']:\n","                context = passage['context']\n","                for qa in passage['qas']:\n","                    question = qa['question']\n","                    if self.mode == 'test':\n","                        contexts.append(context)\n","                        questions.append(question)\n","                        question_ids.append(qa['question_id'])\n","                    else: # train or val\n","                        for ans in qa['answers']:\n","                            contexts.append(context)\n","                            questions.append(question)\n","\n","                            if qa['is_impossible']:\n","                                answers.append({'text':'','answer_start':-1})\n","                            else:\n","                                answers.append(ans)\n","                \n","        # return formatted data lists\n","        return contexts, questions, answers, question_ids\n","    \n","    \n","    def add_end_idx(self, answers, contexts):     # train.json에는 질문에 대한 답이 context 내에서 시작되는 index인 'answer_srart'만 있기 때문에, 추가로 'answer_end'를 찾아주는 함수\n","        for answer, context in zip(answers, contexts):\n","            gold_text = answer['text']\n","            start_idx = answer['answer_start']\n","            end_idx = start_idx + len(gold_text)\n","\n","            # in case the indices are off 1-2 idxs\n","            if context[start_idx:end_idx] == gold_text:\n","                answer['answer_end'] = end_idx\n","            else:\n","                for n in [1, 2]:\n","                    if context[start_idx-n:end_idx-n] == gold_text:\n","                        answer['answer_start'] = start_idx - n\n","                        answer['answer_end'] = end_idx - n\n","                    elif context[start_idx+n:end_idx+n] == gold_text:\n","                        answer['answer_start'] = start_idx + n\n","                        answer['answer_end'] = end_idx + n\n","                        \n","\n","    def add_token_positions(self, encodings, answers):\n","        # should use Fast tokenizer\n","        start_positions = []\n","        end_positions = []\n","        for i in range(len(answers)):\n","            if answers[i]['answer_start'] == -1:\n","                # set [CLS] token as answer if is_impossible\n","                start_positions.append(0)\n","                end_positions.append(1)\n","            else:\n","                start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n","\n","                assert 'answer_end' in answers[i].keys(), f'no answer_end at {i}'\n","                end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n","\n","            # answer passage truncated\n","            if start_positions[-1] is None:\n","                start_positions[-1] = tokenizer.model_max_length                \n","            # end position cannot be found, shift until found\n","            shift = 1\n","            while end_positions[-1] is None:\n","                end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n","                shift += 1\n","                \n","        # char-based -> token based\n","        encodings.update({'start_positions': start_positions, 'end_positions': end_positions})"],"id":"2c5fa64b-a355-43d2-95dc-94bb8605cc15"},{"cell_type":"markdown","metadata":{"id":"c5842a98-c4d9-477c-bfbb-db93a1bdca32"},"source":["##4. 모델 정의"],"id":"c5842a98-c4d9-477c-bfbb-db93a1bdca32"},{"cell_type":"code","execution_count":null,"metadata":{"id":"69904ef0-ec62-4eb2-8540-9f44a112fc1c"},"outputs":[],"source":["class electra(nn.Module):     # pytorch의 모든 neural network 모델들은 torch.nn.Module 클래스를 상속해야 한다. 기본적으로 __init__()과 forward 함수가 override(재정의)되어야 하며, forward 함수는 모델의 계산을 실행하는 것을 뜻한다.\n","\n","    def __init__(self, pretrained, **kwargs):\n","        super(electra, self).__init__()\n","\n","        self.model = ElectraForQuestionAnswering.from_pretrained(pretrained)     # Hugging Face에서 pretrain된 모델을 가져와서 model 변수에 저장한다.\n","        \n","\n","    def forward(self, input_ids, attention_mask, start_positions=None, end_positions=None):\n","        \n","        outputs = self.model(input_ids = input_ids, \n","                             attention_mask = attention_mask,\n","                             start_positions = start_positions,\n","                             end_positions = end_positions)\n","        \n","        return outputs"],"id":"69904ef0-ec62-4eb2-8540-9f44a112fc1c"},{"cell_type":"markdown","metadata":{"id":"9615d17d-1f80-45e9-8583-e4b3f3a84f44"},"source":["##5. Utils 정의\n","###5.1 EarlyStopper"],"id":"9615d17d-1f80-45e9-8583-e4b3f3a84f44"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9ea7473-7a39-48d9-a0c7-5ef197c99547"},"outputs":[],"source":["class EarlyStopper():     # 일정 기간 모델 성능에 개선이 없으면, 학습을 중단하는 기능\n","\n","    def __init__(self, patience: int, mode:str)-> None:\n","        self.patience = patience\n","        self.mode = mode\n","\n","        # Initiate\n","        self.patience_counter = 0\n","        self.stop = False\n","        self.best_loss = np.inf\n","\n","        print(f\"Initiated early stopper, mode: {self.mode}, best score: {self.best_loss}, patience: {self.patience}\")\n","\n","        \n","    def check_early_stopping(self, loss: float)-> None:\n","        loss = -loss if self.mode == 'max' else loss  # get max value if mode set to max\n","\n","        if loss > self.best_loss:\n","            # got worse score\n","            self.patience_counter += 1\n","\n","            print(f\"Early stopper, counter {self.patience_counter}/{self.patience}, best:{abs(self.best_loss)} -> now:{abs(loss)}\")\n","            \n","            if self.patience_counter == self.patience:\n","                print(f\"Early stopper, stop\")\n","                self.stop = True  # end\n","\n","        elif loss <= self.best_loss:\n","            # got better score\n","            self.patience_counter = 0\n","            \n","            print(f\"Early stopper, counter {self.patience_counter}/{self.patience}, best:{abs(self.best_loss)} -> now:{abs(loss)}\")\n","            print(f\"Set counter as {self.patience_counter}\")\n","            print(f\"Update best score as {abs(loss)}\")\n","            \n","            self.best_loss = loss\n","            \n","        else:\n","            print('debug')"],"id":"e9ea7473-7a39-48d9-a0c7-5ef197c99547"},{"cell_type":"markdown","metadata":{"id":"c53b4cda-5607-4a52-ad4b-a0ae33940004"},"source":["###5.2 Trainer"],"id":"c53b4cda-5607-4a52-ad4b-a0ae33940004"},{"cell_type":"code","execution_count":null,"metadata":{"id":"636e914f-d8cb-47b4-8fa0-3f6918653ae0"},"outputs":[],"source":["class Trainer():     # 학습을 위한 Trainer 클래스 정의\n","\n","    def __init__(self,\n","                 model,\n","                 optimizer,\n","                 loss,\n","                 metrics,\n","                 device,\n","                 tokenizer,\n","                 interval=100):\n","        \n","        self.model = model\n","        self.optimizer = optimizer\n","        self.loss = loss\n","        self.metrics = metrics\n","        self.device = device\n","        self.interval = interval\n","        self.tokenizer = tokenizer\n","\n","        # History\n","        self.loss_sum = 0  # Epoch loss sum\n","        self.loss_mean = 0 # Epoch loss mean\n","        self.y = list()\n","        self.y_preds = list()\n","        self.score_dict = dict()  # metric score\n","        self.elapsed_time = 0\n","        \n","\n","    def train(self, mode, dataloader, tokenizer, epoch_index=0):\n","        \n","        start_timestamp = time()\n","        self.model.train() if mode == 'train' else self.model.eval()     # 모델을 train(eval) mode로 전환.  train(eval) mode에서는 dropout, batchnorm이 적용된다(적용되지 않는다)\n"," \n","        for batch_index, batch in enumerate(tqdm(dataloader, leave=True)):\n","            \n","            self.optimizer.zero_grad()     # 파라미터 업데이트는 batch 단위로 이루어지고, 매 batch마다 이전 스템에서 계산된 gradient를 초기화해주어야 함\n","            # pull all the tensor batches required for training\n","            input_ids = batch['input_ids'].to(self.device)\n","            attention_mask = batch['attention_mask'].to(self.device)\n","            start_positions = batch['start_positions'].to(self.device)\n","            end_positions = batch['end_positions'].to(self.device)\n","            \n","            # train model on batch and return outputs (incl. loss)\n","            # Inference\n","            outputs = self.model(input_ids, attention_mask=attention_mask,\n","                            start_positions=start_positions,\n","                            end_positions=end_positions)\n","            \n","            loss = outputs.loss\n","            start_score = outputs.start_logits\n","            end_score = outputs.end_logits\n","            \n","            \n","            start_idx = torch.argmax(start_score, dim=1).cpu().tolist()\n","            end_idx = torch.argmax(end_score, dim=1).cpu().tolist()\n","            \n","            # Update\n","            if mode == 'train':\n","                loss.backward()     # backpropagation\n","                self.optimizer.step()     # 파라미터 업데이트\n","                \n","            elif mode in ['val', 'test']:\n","                pass\n","            \n","            # History\n","            self.loss_sum += loss.item()\n","            \n","            # create answer; list of strings\n","            for i in range(len(input_ids)):\n","                if start_idx[i] > end_idx[i]:\n","                    output = ''\n","                \n","                self.y_preds.append(self.tokenizer.decode(input_ids[i][start_idx[i]:end_idx[i]]))\n","                self.y.append(self.tokenizer.decode(input_ids[i][start_positions[i]:end_positions[i]]))\n","\n","\n","            # Logging\n","            if batch_index % self.interval == 0:\n","                print(f\"batch: {batch_index}/{len(dataloader)} loss: {loss.item()}\")\n","                \n","        # Epoch history\n","        self.loss_mean = self.loss_sum / len(dataloader)  # Epoch loss mean\n","\n","        # Metric\n","        score = self.metrics(self.y, self.y_preds)\n","        self.score_dict['metric_name'] = score\n","\n","        # Elapsed time\n","        end_timestamp = time()\n","        self.elapsed_time = end_timestamp - start_timestamp\n","\n","    def clear_history(self):\n","        self.loss_sum = 0\n","        self.loss_mean = 0\n","        self.y_preds = list()\n","        self.y = list()\n","        self.score_dict = dict()\n","        self.elapsed_time = 0"],"id":"636e914f-d8cb-47b4-8fa0-3f6918653ae0"},{"cell_type":"markdown","metadata":{"id":"1f530fc6-25e7-4b9c-9431-7a5ea267c348"},"source":["###5.3 Recorder"],"id":"1f530fc6-25e7-4b9c-9431-7a5ea267c348"},{"cell_type":"code","execution_count":null,"metadata":{"id":"89b61d3c-858b-4213-a1c1-8f32bed3698a"},"outputs":[],"source":["class Recorder():\n","\n","    def __init__(self,\n","                 record_dir: str,\n","                 model: object,\n","                 optimizer: object):\n","        \n","        self.record_dir = record_dir\n","        self.record_filepath = os.path.join(self.record_dir, 'record.csv')\n","        self.weight_path = os.path.join(record_dir, 'model.pt')\n","\n","        self.model = model\n","        self.optimizer = optimizer\n","\n","        \n","    def set_model(self, model: 'model'):\n","        self.model = model\n","\n","\n","    def add_row(self, row_dict: dict):\n","\n","        fieldnames = list(row_dict.keys())\n","\n","        with open(self.record_filepath, newline='', mode='a') as f:\n","            writer = csv.DictWriter(f, fieldnames=fieldnames)\n","\n","            if f.tell() == 0:\n","                writer.writeheader()\n","\n","            writer.writerow(row_dict)\n","            print(f\"Write row {row_dict['epoch_index']}\")\n","\n","            \n","    def save_weight(self, epoch: int)-> None:\n","        check_point = {\n","            'epoch': epoch + 1,\n","            'model': self.model.state_dict(),\n","            'optimizer': self.optimizer.state_dict(),\n","        }\n","        \n","        torch.save(check_point, self.weight_path)\n","        print(f\"Recorder, epoch {epoch} Model saved: {self.weight_path}\")"],"id":"89b61d3c-858b-4213-a1c1-8f32bed3698a"},{"cell_type":"markdown","metadata":{"id":"66c1c276-2264-43b9-aa62-44cfd81ee395"},"source":["##6. 모델 학습"],"id":"66c1c276-2264-43b9-aa62-44cfd81ee395"},{"cell_type":"markdown","metadata":{"id":"aa925da6-d006-4fb9-a763-021ffe9bc8e4"},"source":["###6.1 모델과 기타 utils 설정"],"id":"aa925da6-d006-4fb9-a763-021ffe9bc8e4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"714f8a41-c14f-4fc5-84ae-b04f0452a952"},"outputs":[],"source":["# Load model\n","model = electra(pretrained='monologg/koelectra-small-v3-discriminator').to(device)\n","\n","# Set optimizer, loss function, metric function\n","optimizer = optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","loss = F.cross_entropy\n","metrics = accuracy_score\n","\n","# Set tokenizer\n","tokenizer = ElectraTokenizerFast.from_pretrained('monologg/koelectra-small-v3-discriminator')\n","\n","# Set Trainer\n","trainer = Trainer(model=model,\n","                  optimizer=optimizer,\n","                  loss=loss,\n","                  metrics=metrics,\n","                  device=device,\n","                  tokenizer=tokenizer,\n","                  interval=LOGGING_INTERVAL)\n","\n","# Set earlystopper\n","early_stopper = EarlyStopper(patience=EARLY_STOPPING_PATIENCE,\n","                            mode=min)\n","\n","# Set train serial\n","kst = timezone(timedelta(hours=9))\n","train_serial = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n","\n","\n","# Set recorder \n","RECORDER_DIR = os.path.join(PROJECT_DIR, 'results', 'train', train_serial)\n","os.makedirs(RECORDER_DIR, exist_ok=True)\n","\n","recorder = Recorder(record_dir=RECORDER_DIR,\n","                    model=model,\n","                    optimizer=optimizer)"],"id":"714f8a41-c14f-4fc5-84ae-b04f0452a952"},{"cell_type":"markdown","metadata":{"id":"c715ceb0-4555-431a-ab9d-8f6f99dd783f"},"source":["###6.2 Dataset & Dataloader 설정"],"id":"c715ceb0-4555-431a-ab9d-8f6f99dd783f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d504be1e-67c8-4de5-b8d0-225ac0b8fd65"},"outputs":[],"source":["# torch.utils.data.Dataset : 데이터를 input으로 변환\n","train_dataset = QADataset(data_dir=os.path.join(DATA_DIR, 'train.json'), tokenizer = tokenizer, max_seq_len = 512, mode = 'train')\n","val_dataset = QADataset(data_dir=os.path.join(DATA_DIR, 'train.json'), tokenizer = tokenizer, max_seq_len = 512, mode = 'val')\n","\n","# torch.utils.data.DataLoader : input을 배치 단위로 리턴해주는 기능\n","train_dataloader = DataLoader(dataset=train_dataset,\n","                              batch_size=BATCH_SIZE,\n","                              num_workers=NUM_WORKERS, \n","                              shuffle=True,\n","                              pin_memory=PIN_MEMORY,\n","                              drop_last=DROP_LAST)\n","\n","val_dataloader = DataLoader(dataset=val_dataset,\n","                            batch_size=BATCH_SIZE,\n","                            num_workers=NUM_WORKERS, \n","                            shuffle=False,\n","                            pin_memory=PIN_MEMORY,\n","                            drop_last=DROP_LAST)\n","\n","print(f\"Load data, train:{len(train_dataset)} val:{len(val_dataset)}\")"],"id":"d504be1e-67c8-4de5-b8d0-225ac0b8fd65"},{"cell_type":"markdown","metadata":{"id":"3e685537-7c8b-439c-8258-00c658bb360a"},"source":["###6.3 Epoch 단위 학습 진행"],"id":"3e685537-7c8b-439c-8258-00c658bb360a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"661bf57c-20d2-4e14-bffb-e7db7eb85f78"},"outputs":[],"source":["# Train\n","for epoch_index in range(EPOCHS):\n","\n","    # Set Recorder row\n","    row_dict = dict()\n","    row_dict['epoch_index'] = epoch_index\n","    row_dict['train_serial'] = train_serial\n","\n","    \"\"\"\n","    Train\n","    \"\"\"\n","    print(f\"Train {epoch_index}/{EPOCHS}\")\n","    print(f\"--Train {epoch_index}/{EPOCHS}\")\n","    trainer.train(dataloader=train_dataloader, epoch_index=epoch_index, tokenizer=tokenizer, mode='train')\n","\n","    row_dict['train_loss'] = trainer.loss_mean\n","    row_dict['train_elapsed_time'] = trainer.elapsed_time \n","\n","    for metric_str, score in trainer.score_dict.items():\n","        row_dict[f\"train_{metric_str}\"] = score\n","    trainer.clear_history()\n","\n","    \"\"\"\n","    Validation\n","    \"\"\"\n","    print(f\"Val {epoch_index}/{EPOCHS}\")\n","    print(f\"--Val {epoch_index}/{EPOCHS}\")\n","    trainer.train(dataloader=val_dataloader, epoch_index=epoch_index, tokenizer=tokenizer, mode='val')\n","\n","    row_dict['val_loss'] = trainer.loss_mean\n","    row_dict['val_elapsed_time'] = trainer.elapsed_time \n","\n","    for metric_str, score in trainer.score_dict.items():\n","        row_dict[f\"val_{metric_str}\"] = score\n","    trainer.clear_history()\n","\n","    \"\"\"\n","    Record\n","    \"\"\"\n","    recorder.add_row(row_dict)\n","\n","    \"\"\"\n","    Early stopper\n","    \"\"\"\n","    early_stopping_target = EARLY_STOPPING_TARGET\n","    early_stopper.check_early_stopping(loss=row_dict[early_stopping_target])\n","\n","    if early_stopper.patience_counter == 0:\n","        recorder.save_weight(epoch=epoch_index)\n","        best_row_dict = copy.deepcopy(row_dict)\n","\n","    if early_stopper.stop == True:\n","        print(f\"Early stopped, counter {early_stopper.patience_counter}/{EARLY_STOPPING_PATIENCE}\")\n","\n","        break"],"id":"661bf57c-20d2-4e14-bffb-e7db7eb85f78"},{"cell_type":"markdown","metadata":{"id":"ed9d2987-378c-45df-84bf-ee4589ac61d4"},"source":["##7. 추론"],"id":"ed9d2987-378c-45df-84bf-ee4589ac61d4"},{"cell_type":"markdown","metadata":{"id":"0dee7dae-24d0-4cf3-b641-c3938ceda233"},"source":["###7.1 테스트 Dataset & Dataloader 설정"],"id":"0dee7dae-24d0-4cf3-b641-c3938ceda233"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a67fcd63-de84-41fe-a620-8771d799722b"},"outputs":[],"source":["# Load data\n","test_dataset = QADataset(data_dir=os.path.join(DATA_DIR, 'test.json'), tokenizer = tokenizer, max_seq_len = 512, mode = 'test')\n","\n","question_ids = test_dataset.question_ids\n","\n","test_dataloader = DataLoader(dataset=test_dataset,\n","                            batch_size=BATCH_SIZE,\n","                            num_workers=NUM_WORKERS, \n","                            shuffle=False,\n","                            pin_memory=PIN_MEMORY,\n","                            drop_last=DROP_LAST)"],"id":"a67fcd63-de84-41fe-a620-8771d799722b"},{"cell_type":"markdown","metadata":{"id":"733f8fc5-d1e8-4027-b8c7-ed87ec409246"},"source":["###7.2 모델 로드"],"id":"733f8fc5-d1e8-4027-b8c7-ed87ec409246"},{"cell_type":"code","execution_count":null,"metadata":{"id":"86cc6eeb-6f7c-4765-9478-83cb9ce62954"},"outputs":[],"source":["# Load model\n","\n","model = electra(pretrained='monologg/koelectra-small-v3-discriminator').to(device)\n","\n","checkpoint = torch.load(os.path.join(RECORDER_DIR, 'model.pt'))\n","\n","model.load_state_dict(checkpoint['model'])"],"id":"86cc6eeb-6f7c-4765-9478-83cb9ce62954"},{"cell_type":"markdown","metadata":{"id":"ea6e2ce2-c11a-42b0-baaa-107251e077a3"},"source":["###7.3 추론 진행"],"id":"ea6e2ce2-c11a-42b0-baaa-107251e077a3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"6876e75d-f3ba-4007-a548-062d4b1ce681"},"outputs":[],"source":["model.eval()     # 모델을 eval mode로 전환. train mode와 달리 eval mode에서는 dropout, batchnorm이 적용되지 않는다\n","\n","pred_df = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'))\n","\n","for batch_index, batch in enumerate(tqdm(test_dataloader, leave=True)):\n","    input_ids = batch['input_ids'].to(device)\n","    attention_mask = batch['attention_mask'].to(device)\n","\n","    # Inference\n","    outputs = model(input_ids, attention_mask=attention_mask)\n","\n","    start_score = outputs.start_logits\n","    end_score = outputs.end_logits\n","\n","    start_idx = torch.argmax(start_score, dim=1).cpu().tolist()\n","    end_idx = torch.argmax(end_score, dim=1).cpu().tolist()\n","\n","    y_pred = []\n","    for i in range(len(input_ids)):\n","        if start_idx[i] > end_idx[i]:\n","            output = ''\n","\n","        ans_txt = tokenizer.decode(input_ids[i][start_idx[i]:end_idx[i]]).replace('#','')\n","\n","        if ans_txt == '[CLS]':\n","            ans_txt == ''\n","\n","        y_pred.append(ans_txt)\n","\n","\n","    q_end_idx = BATCH_SIZE*batch_index + len(y_pred)\n","    for q_id, pred in zip(question_ids[BATCH_SIZE*batch_index:q_end_idx], y_pred):\n","        pred_df.loc[pred_df['question_id'] == q_id,'answer_text'] = pred"],"id":"6876e75d-f3ba-4007-a548-062d4b1ce681"},{"cell_type":"markdown","metadata":{"id":"2860d018-7dda-434f-97ef-cd59a0572c92"},"source":["###7.4 결과 저장"],"id":"2860d018-7dda-434f-97ef-cd59a0572c92"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8f98cd03-5a99-4911-a72e-bc81e49c18be"},"outputs":[],"source":["# Set predict serial\n","kst = timezone(timedelta(hours=9))\n","predict_timestamp = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n","predict_serial = predict_timestamp\n","predict_serial\n","\n","PREDICT_DIR = os.path.join(PROJECT_DIR, 'results', 'predict', predict_serial)\n","os.makedirs(PREDICT_DIR, exist_ok=True)\n","\n","pred_df.to_csv(os.path.join(PREDICT_DIR, 'prediction.csv'), index=False)"],"id":"8f98cd03-5a99-4911-a72e-bc81e49c18be"},{"cell_type":"code","execution_count":null,"metadata":{"id":"SX6apf0nRz1Y"},"outputs":[],"source":[],"id":"SX6apf0nRz1Y"}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":5}